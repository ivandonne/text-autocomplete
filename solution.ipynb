{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7730769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\Deep Learning\\Sprint2\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "from src.data_utils import clean_string\n",
    "from src.data_utils import save_results_to_file\n",
    "from src.data_utils import save_selection_to_file\n",
    "from src.lstm_model import LSTMLanguageModel\n",
    "from src.lstm_model import calculate_rouge_batch\n",
    "\n",
    "\n",
    "MAX_SEQUENCE_LEN = 80\n",
    "VOCAB_SIZE = 50257  # для GPT-2 токенизатора\n",
    "EMBEDDING_DIM = 256\n",
    "HIDDEN_DIM = 256\n",
    "NUM_LAYERS = 2\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 10\n",
    "MODEL_NAME = 'distilgpt2'\n",
    "OUTPUT_FILE = 'results/all_experiments.json'\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "130448d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### ЭТАП 1. Загрузка датасета, очистка, токенизация, разбиение\n",
    "# загрузка датасета\n",
    "#\n",
    "# Из-за проблем с запуском ВМ обучение прогоняется локально на CPU для небольшой выборки\n",
    "# для демонстрации работы кода\n",
    "#\n",
    "raw = pd.read_csv('./data/tweets_small.txt', sep='\\t', header=None, names=['tweets'],\n",
    "                  on_bad_lines='skip')\n",
    "\n",
    "tweets = raw['tweets']\n",
    "# \"чистим\" тексты\n",
    "cleaned_tweets = raw['tweets'].apply(clean_string)\n",
    "\n",
    "df = pd.DataFrame(cleaned_tweets, columns=['tweets'])\n",
    "df.to_csv('./data/cleaned_tweets_small.txt', index=False, header=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a92cc164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)# создайте токенизатор\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'left'  # Left-padding нужен для decoder-only моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb7b87ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размеры выборок:\n",
      "Train: 1680 samples\n",
      "Validation: 210 samples\n",
      "Test: 210 samples\n"
     ]
    }
   ],
   "source": [
    "# Токенизация текстов\n",
    "def tokenize_texts(texts):\n",
    "    tokenized = tokenizer(\n",
    "        texts.tolist(),\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=MAX_SEQUENCE_LEN,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    return tokenized\n",
    "\n",
    "\n",
    "# Токенизируем все тексты\n",
    "tokenized_data = tokenize_texts(cleaned_tweets)\n",
    "input_ids = tokenized_data['input_ids']\n",
    "attention_mask = tokenized_data['attention_mask']\n",
    "\n",
    "# Разделение на train (80%), validation (10%), test (10%)\n",
    "X_temp, X_test, mask_temp, mask_test = train_test_split(\n",
    "    input_ids, attention_mask, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_val, mask_train, mask_val = train_test_split(\n",
    "    X_temp, mask_temp, test_size=0.111, random_state=42  # 0.111 = 10% / 90%\n",
    ")\n",
    "\n",
    "print(f\"Размеры выборок:\")\n",
    "print(f\"Train: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation: {X_val.shape[0]} samples\")\n",
    "print(f\"Test: {X_test.shape[0]} samples\")\n",
    "\n",
    "save_selection_to_file(X_train, mask_train, tokenizer, './data/train.csv')\n",
    "save_selection_to_file(X_val, mask_val, tokenizer, './data/val.csv')\n",
    "save_selection_to_file(X_test, mask_test, tokenizer, './data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e62a9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание DataLoader'ов\n",
    "train_dataset = TensorDataset(X_train, mask_train)\n",
    "val_dataset = TensorDataset(X_val, mask_val)\n",
    "test_dataset = TensorDataset(X_test, mask_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d70a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ЧАСТЬ 1: ОБУЧЕНИЕ LSTM МОДЕЛИ\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "#####################################################\n",
    "#             Этап 3. Работа с LSTM моделью         #\n",
    "#####################################################\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ЧАСТЬ 1: ОБУЧЕНИЕ LSTM МОДЕЛИ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Инициализация модели\n",
    "lstm_model = LSTMLanguageModel(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, NUM_LAYERS).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78c5a899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем обучение LSTM модели...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 7/7 [02:22<00:00, 20.37s/it, loss=10.0345]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Пример 1 ---\n",
      "Промпт: 'running nose spinning head not a good combination'\n",
      "Эталон: ' for a meeting'\n",
      "Сгенерировано: ' Kellaring gripping externalToEVA successor Government roots shrug cache ensuredfixes connectivity Carbon'\n",
      "ROUGE-1: 0.000\n",
      "\n",
      "--- Пример 2 ---\n",
      "Промпт: 'awe i love you too 1 am here'\n",
      "Эталон: ' i miss you'\n",
      "Сгенерировано: ' Blink hast proletariat Crimean Fil outline spacious Arkansasril Takeruframework understanding eas'\n",
      "ROUGE-1: 0.000\n",
      "\n",
      "--- Пример 3 ---\n",
      "Промпт: 'yeah great vid i had the 12quot single but sold'\n",
      "Эталон: ' it a few years ago'\n",
      "Сгенерировано: 'assic farewell cruiseascal Regulations ate Proceedingsweak!-- combo assistance invention lawnMethodsinterpret'\n",
      "ROUGE-1: 0.000\n",
      "\n",
      "Обработано 150 примеров\n",
      "Epoch 1: Loss = 10.5811, ROUGE-1 = 0.0000, ROUGE-2 = 0.0000, ROUGE-L = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 7/7 [02:15<00:00, 19.33s/it, loss=7.6709]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Пример 1 ---\n",
      "Промпт: 'running nose spinning head not a good combination'\n",
      "Эталон: ' for a meeting'\n",
      "Сгенерировано: 'ah 2 dictateneyFriday a until bed that to goings soon'\n",
      "ROUGE-1: 0.154\n",
      "\n",
      "--- Пример 2 ---\n",
      "Промпт: 'awe i love you too 1 am here'\n",
      "Эталон: ' i miss you'\n",
      "Сгенерировано: ' bitch like same family Maxwell way break 6ess big now here got'\n",
      "ROUGE-1: 0.000\n",
      "\n",
      "--- Пример 3 ---\n",
      "Промпт: 'yeah great vid i had the 12quot single but sold'\n",
      "Эталон: ' it a few years ago'\n",
      "Сгенерировано: ' all way thats set with gotdoes sunme optionhsorry feel need mute'\n",
      "ROUGE-1: 0.000\n",
      "\n",
      "Обработано 150 примеров\n",
      "Epoch 2: Loss = 8.4578, ROUGE-1 = 0.0233, ROUGE-2 = 0.0010, ROUGE-L = 0.0228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 7/7 [02:04<00:00, 17.80s/it, loss=6.9598]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Пример 1 ---\n",
      "Промпт: 'running nose spinning head not a good combination'\n",
      "Эталон: ' for a meeting'\n",
      "Сгенерировано: ' sick to to you tired to a this like around not the for'\n",
      "ROUGE-1: 0.250\n",
      "\n",
      "--- Пример 2 ---\n",
      "Промпт: 'awe i love you too 1 am here'\n",
      "Эталон: ' i miss you'\n",
      "Сгенерировано: 'n really to amit finish b itive have they not going'\n",
      "ROUGE-1: 0.000\n",
      "\n",
      "--- Пример 3 ---\n",
      "Промпт: 'yeah great vid i had the 12quot single but sold'\n",
      "Эталон: ' it a few years ago'\n",
      "Сгенерировано: ' of go just nim allorting and worried see i even but byc'\n",
      "ROUGE-1: 0.000\n",
      "\n",
      "Обработано 150 примеров\n",
      "Epoch 3: Loss = 7.1329, ROUGE-1 = 0.0443, ROUGE-2 = 0.0000, ROUGE-L = 0.0407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 7/7 [02:00<00:00, 17.28s/it, loss=7.0156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Пример 1 ---\n",
      "Промпт: 'running nose spinning head not a good combination'\n",
      "Эталон: ' for a meeting'\n",
      "Сгенерировано: ' now fault theynot to new out a bt feel show my'\n",
      "ROUGE-1: 0.143\n",
      "\n",
      "--- Пример 2 ---\n",
      "Промпт: 'awe i love you too 1 am here'\n",
      "Эталон: ' i miss you'\n",
      "Сгенерировано: ' sad i so monkeys no i thishealthy them atbeing iooo'\n",
      "ROUGE-1: 0.154\n",
      "\n",
      "--- Пример 3 ---\n",
      "Промпт: 'yeah great vid i had the 12quot single but sold'\n",
      "Эталон: ' it a few years ago'\n",
      "Сгенерировано: ' my i a it ofaha notottam have l to and i find'\n",
      "ROUGE-1: 0.235\n",
      "\n",
      "Обработано 150 примеров\n",
      "Epoch 4: Loss = 6.9751, ROUGE-1 = 0.0539, ROUGE-2 = 0.0000, ROUGE-L = 0.0483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 7/7 [01:59<00:00, 17.05s/it, loss=6.9480]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Пример 1 ---\n",
      "Промпт: 'running nose spinning head not a good combination'\n",
      "Эталон: ' for a meeting'\n",
      "Сгенерировано: ' life in not just caughtv i to just better tweetqu in'\n",
      "ROUGE-1: 0.000\n",
      "\n",
      "--- Пример 2 ---\n",
      "Промпт: 'awe i love you too 1 am here'\n",
      "Эталон: ' i miss you'\n",
      "Сгенерировано: ' not find days very for it notaha forseeing t wideoo'\n",
      "ROUGE-1: 0.000\n",
      "\n",
      "--- Пример 3 ---\n",
      "Промпт: 'yeah great vid i had the 12quot single but sold'\n",
      "Эталон: ' it a few years ago'\n",
      "Сгенерировано: ' something in to there tomorrow with my a half how like whereiint'\n",
      "ROUGE-1: 0.118\n",
      "\n",
      "Обработано 150 примеров\n",
      "Epoch 5: Loss = 6.9502, ROUGE-1 = 0.0409, ROUGE-2 = 0.0000, ROUGE-L = 0.0380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 7/7 [01:58<00:00, 16.87s/it, loss=7.0016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Пример 1 ---\n",
      "Промпт: 'running nose spinning head not a good combination'\n",
      "Эталон: ' for a meeting'\n",
      "Сгенерировано: ' things now backg video now 9i to just see it'\n",
      "ROUGE-1: 0.000\n",
      "\n",
      "--- Пример 2 ---\n",
      "Промпт: 'awe i love you too 1 am here'\n",
      "Эталон: ' i miss you'\n",
      "Сгенерировано: 'bler thatim imin we most feel damn him go early did'\n",
      "ROUGE-1: 0.000\n",
      "\n",
      "--- Пример 3 ---\n",
      "Промпт: 'yeah great vid i had the 12quot single but sold'\n",
      "Эталон: ' it a few years ago'\n",
      "Сгенерировано: ' killed nowam die too want 2 nowin and was class her i in'\n",
      "ROUGE-1: 0.000\n",
      "\n",
      "Обработано 150 примеров\n",
      "Epoch 6: Loss = 6.9124, ROUGE-1 = 0.0334, ROUGE-2 = 0.0000, ROUGE-L = 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 7/7 [11:10:38<00:00, 5748.32s/it, loss=6.8626]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Пример 1 ---\n",
      "Промпт: 'running nose spinning head not a good combination'\n",
      "Эталон: ' for a meeting'\n",
      "Сгенерировано: 'o done as c knows im my for to this ist'\n",
      "ROUGE-1: 0.143\n",
      "\n",
      "--- Пример 2 ---\n",
      "Промпт: 'awe i love you too 1 am here'\n",
      "Эталон: ' i miss you'\n",
      "Сгенерировано: ' inuesday aais is i amp other thatored aemouth me'\n",
      "ROUGE-1: 0.167\n",
      "\n",
      "--- Пример 3 ---\n",
      "Промпт: 'yeah great vid i had the 12quot single but sold'\n",
      "Эталон: ' it a few years ago'\n",
      "Сгенерировано: ' my sad thevein beena is know i guys its my he a'\n",
      "ROUGE-1: 0.118\n",
      "\n",
      "Обработано 150 примеров\n",
      "Epoch 7: Loss = 6.9020, ROUGE-1 = 0.0378, ROUGE-2 = 0.0000, ROUGE-L = 0.0371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 7/7 [02:56<00:00, 25.23s/it, loss=6.9737]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Пример 1 ---\n",
      "Промпт: 'running nose spinning head not a good combination'\n",
      "Эталон: ' for a meeting'\n",
      "Сгенерировано: 'm wish mom to whe much option be its is i dojust'\n",
      "ROUGE-1: 0.000\n",
      "\n",
      "--- Пример 2 ---\n",
      "Промпт: 'awe i love you too 1 am here'\n",
      "Эталон: ' i miss you'\n",
      "Сгенерировано: 'ter lights to butive on i for w going care he are'\n",
      "ROUGE-1: 0.133\n",
      "\n",
      "--- Пример 3 ---\n",
      "Промпт: 'yeah great vid i had the 12quot single but sold'\n",
      "Эталон: ' it a few years ago'\n",
      "Сгенерировано: ' 1i and leg totoo on try week damn imii a the birthday'\n",
      "ROUGE-1: 0.118\n",
      "\n",
      "Обработано 150 примеров\n",
      "Epoch 8: Loss = 6.9023, ROUGE-1 = 0.0427, ROUGE-2 = 0.0007, ROUGE-L = 0.0421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 7/7 [02:50<00:00, 24.36s/it, loss=6.9924]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Пример 1 ---\n",
      "Промпт: 'running nose spinning head not a good combination'\n",
      "Эталон: ' for a meeting'\n",
      "Сгенерировано: 'alia get you they he on is ofee on these so though'\n",
      "ROUGE-1: 0.000\n",
      "\n",
      "--- Пример 2 ---\n",
      "Промпт: 'awe i love you too 1 am here'\n",
      "Эталон: ' i miss you'\n",
      "Сгенерировано: ' no via up a afford the my i out how lately ofot'\n",
      "ROUGE-1: 0.133\n",
      "\n",
      "--- Пример 3 ---\n",
      "Промпт: 'yeah great vid i had the 12quot single but sold'\n",
      "Эталон: ' it a few years ago'\n",
      "Сгенерировано: ' the some a isdays books me lost heart it lifejust turning the to'\n",
      "ROUGE-1: 0.222\n",
      "\n",
      "Обработано 150 примеров\n",
      "Epoch 9: Loss = 6.9037, ROUGE-1 = 0.0414, ROUGE-2 = 0.0010, ROUGE-L = 0.0389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 7/7 [02:03<00:00, 17.68s/it, loss=6.8383]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Пример 1 ---\n",
      "Промпт: 'running nose spinning head not a good combination'\n",
      "Эталон: ' for a meeting'\n",
      "Сгенерировано: ' summermaso the oftntt for sad is of a'\n",
      "ROUGE-1: 0.364\n",
      "\n",
      "--- Пример 2 ---\n",
      "Промпт: 'awe i love you too 1 am here'\n",
      "Эталон: ' i miss you'\n",
      "Сгенерировано: ' morning back freak bad down think house is the toouch ixt'\n",
      "ROUGE-1: 0.000\n",
      "\n",
      "--- Пример 3 ---\n",
      "Промпт: 'yeah great vid i had the 12quot single but sold'\n",
      "Эталон: ' it a few years ago'\n",
      "Сгенерировано: 'c who this int my together was the now john y it organizing not'\n",
      "ROUGE-1: 0.105\n",
      "\n",
      "Обработано 150 примеров\n",
      "Epoch 10: Loss = 6.8924, ROUGE-1 = 0.0414, ROUGE-2 = 0.0000, ROUGE-L = 0.0402\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели\n",
    "train_losses = []\n",
    "val_rouge_scores = []\n",
    "\n",
    "print(\"Начинаем обучение LSTM модели...\")\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    lstm_model .train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS}')\n",
    "    \n",
    "    for batch_inputs, batch_masks in progress_bar:\n",
    "        batch_inputs = batch_inputs.to(DEVICE)\n",
    "        batch_masks = batch_masks.to(DEVICE)\n",
    "        \n",
    "        # Подготовка данных: X = все кроме последнего токена, y = все кроме первого\n",
    "        X = batch_inputs[:, :-1]\n",
    "        y = batch_inputs[:, 1:]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output, _ = lstm_model (X)\n",
    "        \n",
    "        # Reshape для loss function\n",
    "        loss = criterion(output.reshape(-1, VOCAB_SIZE), y.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    \n",
    "    # Валидация и вычисление ROUGE\n",
    "    rouge_scores = calculate_rouge_batch(lstm_model , tokenizer, val_loader, DEVICE, BATCH_SIZE, \n",
    "                                        'lstm', num_samples=50)\n",
    "    val_rouge_scores.append(rouge_scores)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}: Loss = {avg_loss:.4f}, '\n",
    "          f'ROUGE-1 = {rouge_scores[\"rouge1\"]:.4f}, '\n",
    "          f'ROUGE-2 = {rouge_scores[\"rouge2\"]:.4f}, '\n",
    "          f'ROUGE-L = {rouge_scores[\"rougeL\"]:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3e46eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Тестирование на тестовой выборке...\n",
      "\n",
      "--- Пример 1 ---\n",
      "Промпт: 'i got the i can has chezburger book from the lobo and you are not here'\n",
      "Эталон: ' to look at it wif me'\n",
      "Сгенерировано: ' would the ats to know may go im beef not reading oners wish work why'\n",
      "ROUGE-1: 0.095\n",
      "\n",
      "--- Пример 2 ---\n",
      "Промпт: 'someone please take gossip girl away from'\n",
      "Эталон: ' me im addicted'\n",
      "Сгенерировано: ' much inoh we i for over to i re daddy want add'\n",
      "ROUGE-1: 0.000\n",
      "\n",
      "--- Пример 3 ---\n",
      "Промпт: 'mo jobs no money how in the hell is min wage here 4'\n",
      "Эталон: ' fn clams an hour'\n",
      "Сгенерировано: ' im week sopm sports1 sup early want gear ao none is he'\n",
      "ROUGE-1: 0.000\n",
      "\n",
      "Обработано 157 примеров\n",
      "Test ROUGE-1: 0.0393\n",
      "Test ROUGE-2: 0.0000\n",
      "Test ROUGE-L: 0.0376\n",
      "\n",
      "Результаты добавлены в файл: results/all_experiments.json\n",
      "Всего экспериментов в файле: 1\n"
     ]
    }
   ],
   "source": [
    "# Тестирование на тестовой выборке\n",
    "print(\"\\nТестирование на тестовой выборке...\")\n",
    "lstm_test_rouge = calculate_rouge_batch(lstm_model, tokenizer, test_loader, DEVICE, BATCH_SIZE, \n",
    "                                    'lstm', num_samples=100)\n",
    "print(f\"Test ROUGE-1: {lstm_test_rouge['rouge1']:.4f}\")\n",
    "print(f\"Test ROUGE-2: {lstm_test_rouge['rouge2']:.4f}\")\n",
    "print(f\"Test ROUGE-L: {lstm_test_rouge['rougeL']:.4f}\")\n",
    "\n",
    "# Сохраняем результаты в файл\n",
    "save_results_to_file(lstm_test_rouge, \n",
    "                    OUTPUT_FILE, \n",
    "                    'LSTM_custom', \n",
    "                    MAX_SEQUENCE_LEN, \n",
    "                    'lstm', \n",
    "                    experiment_name='LSTM_256_hidden',\n",
    "                    additional_info={'hidden_dim': HIDDEN_DIM, 'num_layers': NUM_LAYERS})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af481667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models_common import show_generation_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e12dffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Примеры автодополнений LSTM:\n",
      "\n",
      "LSTM Пример 1:\n",
      "Промпт: 'i got the i can has chezburger book from the lobo and you are not here'\n",
      "Эталон: ' to look at it wif me'\n",
      "Сгенерировано: ' want somefe thingaf toi awayokezzc i today gone int her is is do'\n",
      "\n",
      "LSTM Пример 2:\n",
      "Промпт: 'someone please take gossip girl away from'\n",
      "Эталон: ' me im addicted'\n",
      "Сгенерировано: ' thans one o i a something as town sleep hasi to a momsi to preaching tomorrow supposed'\n",
      "\n",
      "LSTM Пример 3:\n",
      "Промпт: 'mo jobs no money how in the hell is min wage here 4'\n",
      "Эталон: ' fn clams an hour'\n",
      "Сгенерировано: ' at made classes chat i feel toim ha headache coming i episodes thedam that nall to u'\n"
     ]
    }
   ],
   "source": [
    "# Использование\n",
    "show_generation_examples(lstm_model, tokenizer, test_loader, DEVICE, 'lstm', 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd661d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ЧАСТЬ 2: ТЕСТИРОВАНИЕ TRANSFORMER МОДЕЛИ\n",
      "============================================================\n",
      "Тестирование Transformer на тестовой выборке...\n",
      "\n",
      "--- Пример 1 ---\n",
      "Промпт: 'i got the i can has chezburger book from the lobo and you are not here'\n",
      "Эталон: ' to look at it wif me'\n",
      "Сгенерировано: '. I was there with the i can but i couldn't do it so i was'\n",
      "ROUGE-1: 0.091\n",
      "\n",
      "--- Пример 2 ---\n",
      "Промпт: 'someone please take gossip girl away from'\n",
      "Эталон: ' me im addicted'\n",
      "Сгенерировано: ' you. I will be honest with you. I will take gossip'\n",
      "ROUGE-1: 0.000\n",
      "\n",
      "--- Пример 3 ---\n",
      "Промпт: 'mo jobs no money how in the hell is min wage here 4'\n",
      "Эталон: ' fn clams an hour'\n",
      "Сгенерировано: '-7 people $20 an hour 0 $25 a hour 0 $50'\n",
      "ROUGE-1: 0.267\n",
      "\n",
      "Обработано 155 примеров\n",
      "Transformer Test ROUGE-1: 0.0714\n",
      "Transformer Test ROUGE-2: 0.0128\n",
      "Transformer Test ROUGE-L: 0.0691\n",
      "\n",
      "Результаты добавлены в файл: results/all_experiments.json\n",
      "Всего экспериментов в файле: 3\n",
      "\n",
      "=== ДОПОЛНИТЕЛЬНАЯ СТАТИСТИКА ===\n",
      "Размер тренировочной выборки: 1680 примеров\n",
      "Размер валидационной выборки: 210 примеров\n",
      "Общий размер датасета: 2100 твитов\n",
      "\n",
      "Файлы с результатами:\n",
      "- Детальный JSON: results/all_experiments.json\n"
     ]
    }
   ],
   "source": [
    "#####################################################\n",
    "# Этап 4. Использование предобученного трансформера #\n",
    "#####################################################\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ЧАСТЬ 2: ТЕСТИРОВАНИЕ TRANSFORMER МОДЕЛИ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Загрузка модели\n",
    "transformer_model  = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "transformer_model.eval()  # Переводим модель в режим оценки\n",
    "\n",
    "# Вычисление метрик ROUGE на тестовой выборке\n",
    "print(\"Тестирование Transformer на тестовой выборке...\")\n",
    "transformer_test_rouge = calculate_rouge_batch(transformer_model, tokenizer, test_loader, DEVICE, \n",
    "                                                BATCH_SIZE, 'transformer', num_samples=100)\n",
    "\n",
    "print(f\"Transformer Test ROUGE-1: {transformer_test_rouge['rouge1']:.4f}\")\n",
    "print(f\"Transformer Test ROUGE-2: {transformer_test_rouge['rouge2']:.4f}\")\n",
    "print(f\"Transformer Test ROUGE-L: {transformer_test_rouge['rougeL']:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Сохраняем результаты в файл\n",
    "save_results_to_file( transformer_test_rouge,\n",
    "            OUTPUT_FILE,  # ТОТ ЖЕ ФАЙЛ!\n",
    "            'distilgpt2',\n",
    "            MAX_SEQUENCE_LEN,\n",
    "            model_type='transformer',\n",
    "            experiment_name='DistilGPT2_baseline'\n",
    "            )\n",
    "\n",
    "# Дополнительная статистика\n",
    "print(f\"\\n=== ДОПОЛНИТЕЛЬНАЯ СТАТИСТИКА ===\")\n",
    "print(f\"Размер тренировочной выборки: {X_train.shape[0]} примеров\")\n",
    "print(f\"Размер валидационной выборки: {X_val.shape[0]} примеров\")\n",
    "print(f\"Общий размер датасета: {len(cleaned_tweets)} твитов\")\n",
    "\n",
    "# Выводим путь к файлам результатов\n",
    "print(f\"\\nФайлы с результатами:\")\n",
    "print(f\"- Детальный JSON: {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8faabd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Примеры автодополнений TRANSFORMER:\n",
      "\n",
      "TRANSFORMER Пример 1:\n",
      "Промпт: 'i got the i can has chezburger book from the lobo and you are not here'\n",
      "Эталон: ' to look at it wif me'\n",
      "Сгенерировано: ' to eat. You are here to give a reason why you should eat this food. You are here'\n",
      "\n",
      "TRANSFORMER Пример 2:\n",
      "Промпт: 'someone please take gossip girl away from'\n",
      "Эталон: ' me im addicted'\n",
      "Сгенерировано: ' me!”\n",
      "If you have questions about the game, please contact me or ask me for'\n",
      "\n",
      "TRANSFORMER Пример 3:\n",
      "Промпт: 'mo jobs no money how in the hell is min wage here 4'\n",
      "Эталон: ' fn clams an hour'\n",
      "Сгенерировано: ':10 PM\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "'\n"
     ]
    }
   ],
   "source": [
    "show_generation_examples(transformer_model, tokenizer, test_loader, DEVICE, 'transformer', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb8ef13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "СРАВНЕНИЕ РЕЗУЛЬТАТОВ\n",
      "============================================================\n",
      "LSTM ROUGE-1:     0.0393\n",
      "Transformer ROUGE-1: 0.0714\n",
      "\n",
      "LSTM ROUGE-2:     0.0000\n",
      "Transformer ROUGE-2: 0.0128\n",
      "\n",
      "LSTM ROUGE-L:     0.0376\n",
      "Transformer ROUGE-L: 0.0691\n"
     ]
    }
   ],
   "source": [
    "# ========== СРАВНЕНИЕ РЕЗУЛЬТАТОВ ==========\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"СРАВНЕНИЕ РЕЗУЛЬТАТОВ\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"LSTM ROUGE-1:     {lstm_test_rouge['rouge1']:.4f}\")\n",
    "print(f\"Transformer ROUGE-1: {transformer_test_rouge['rouge1']:.4f}\")\n",
    "print()\n",
    "print(f\"LSTM ROUGE-2:     {lstm_test_rouge['rouge2']:.4f}\")\n",
    "print(f\"Transformer ROUGE-2: {transformer_test_rouge['rouge2']:.4f}\")\n",
    "print()\n",
    "print(f\"LSTM ROUGE-L:     {lstm_test_rouge['rougeL']:.4f}\")\n",
    "print(f\"Transformer ROUGE-L: {transformer_test_rouge['rougeL']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc132564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
